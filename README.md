# IE_MBD_2020

- This repository contains all the projects implemented during my Master's in Business Analytics & Big Data program while at IE University during October 2019 - July 2020

# [Data Visualization (R - ggplot)](https://github.com/BegonaFrigolet/Data-Visualization_R_Library_ggplot)
- Data of CO2 emissions with a focus on new cars in the UK, the study will focus on a dataset of newly sold cars in the United Kingdom from 2000 to 2013.
- The emphasis will be on CO2 emissions from those cars and other related variables.

- To review the report and code it is recommended to download the HTML file:
[code and HTML](https://github.com/BegonaFrigolet/Data-Visualization_R_Library_ggplot/blob/main/0.Final%20CO2%20Analysis%20HTML.html).
- To review the main insights of the report: [Key Findings](https://github.com/BegonaFrigolet/Data_Vizualization_-R-_ggplot-/blob/main/Final%20HTML.html).


# [Data Visualization (D3.js)](https://github.com/BegonaFrigolet/Data-Visualization_D3.js)
The purpose of this project is to transform the data presented in a bar chart into something more interactive while at the same time keeping the main message. To be able to come up with this final result, We combined various sources with the main ones being a tutorial from FlowingData showing us of to do such a visualization.([the link to the tutorial i] (https://flowingdata.com/2016/08/23/make-a-moving-bubbles-chart-to-show-clustering-and-distributions/) and a graph tweeted by Caitlin Huton.

Data:
The data of the animation can be found in this Link

Final Visualization:
The result with animations can be found in this Link, to learn more about D3 it is recommended to go through the explanations as well as the visualizations.

# [Natural Language Processing](https://github.com/BegonaFrigolet/Natural-Language-Processing)

## Analyzing Domestic Violence through Topic Modelling - All documentation can be found on this [LINK] (https://github.com/BegonaFrigolet/Natural-Language-Processing/tree/main/NLPAssignment_GroupA)

- Domestic Violence is not a pandemic, it’s an epidemic. With Covid-19 ravaging the economy; increasing unemployment such crises are set to become much more frequent. Add another public health crisis to the toll of the new coronavirus: Mounting data suggests that domestic abuse is acting as an opportunistic infection, flourishing in the conditions created by the pandemic.

- By applying Topic Modelling Techniques such as: Latent Dirichlet Allocation (LDA), Hierarchical Dirichlet Process (HDP) and data from Social Media (Reditt & Twitter). We are looking to identify the different topics or classes of the tweets or comments in reddit platform to make the large and unstructured data more organized in a way that will make it easier for NGOs, government officials or researchers to assess and get useful insights from to better analyze this crisis and come up with better courses of actions accordingly.

- To Review  the Website & Application can be found in this [LINK](https://bfdelavega.wixsite.com/misitio)
- To Review  the Final Report can be found in this [LINK](https://github.com/BegonaFrigolet/Natural-Language-Processing/blob/main/NLPAssignment_GroupA/Final%20Report_GroupA.pdf)
- To Review  the Final Presentation can be found in this [LINK](https://github.com/BegonaFrigolet/Natural-Language-Processing/blob/main/NLPAssignment_GroupA/GroupA_Domestic_Violence.pptx)

## Analyzing Disaster Tweets Through NLP All documentation can be found on this [LINK] (https://github.com/BegonaFrigolet/Natural-Language-Processing/tree/main/NLP%20%20Disaster%20Tweets)

### Main Goal: 
The goal is to try to help the prediction of which Tweets are talking about real disasters and which ones are not. The problem is dealing with a binary classification problem classifying them The data set is of 10K tweets that were hand classified, from the company figure-eight and originally shared on their "Data For Everyone" website here.

Tweet source: https://twitter.com/AnyOtherAnnaK/status/629195955506708480

### Techniques:
Due to counter vector giving longer documents I used TF- IDF, which does not only represent if the words are there or not, instead represent the frequency and their inverse document frequency, thus giving less significance to the words that are frequent but appear everywhere, and gives higher value to the words that appears frequently but only in few places.

Other  Techniques Applied: 
- Stop Words
- Removing Punctuation/URL/HTML
- Lemmatization
- Stemming
#### Classifiers: 
- SVM + Lemmatization
- Log Regression + Lemmatization


# [Spark](https://github.com/BegonaFrigolet/SPARK)
- A look into Hotels Reviews:
- The Business world has had a drastically change since the introduction of online companies and their digitalization model in which the largest taxi company does not own cars, the most popular owner does not create their own content and the largest accommodation providers owns no real state.
- Methology: The original data was scraped by Booking.com and they are the owners of the data, for this analysis 2017 was taken into consideration.Through a Virtual Machine and using Spark, data transformations were done with the help of the “PySpark” library.
- To review the report click on this link:
[Code](https://github.com/BegonaFrigolet/SPARK/blob/main/Spark%20-%20Individual%20Assigment-Begon%CC%83a%20Frigolet.pdf).
- To review the code click on this link: 
[Report](https://github.com/BegonaFrigolet/SPARK/blob/main/Begon%CC%83a%20Frigolet-%20Individual%20Assignment%20-%20Hotel%20Review%20Analysis%20-%202017.FINAL.ipynb).
